{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BouTWaBkWfW",
        "outputId": "1cd73566-7734-47da-ca2a-258419a28966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwhlmfFOkayf"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZeQBj_Ikcfc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlaqoQ7fkeSs"
      },
      "outputs": [],
      "source": [
        "positive_df = pd.read_csv('positive_sample_7500_1.csv', header=None)\n",
        "negative_df = pd.read_csv('negative_sample_7500_1.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWkX8eB6kgSU"
      },
      "outputs": [],
      "source": [
        "def load_protein_sequences(file_path):\n",
        "    protein_dict = {}\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                protein_dict[parts[0]] = parts[1]\n",
        "    return protein_dict\n",
        "protein_sequences = load_protein_sequences('protein_sequences.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48CiuEjbkich"
      },
      "outputs": [],
      "source": [
        "positive_df_2 = pd.DataFrame([positive_df[1],positive_df[0]]).transpose()\n",
        "negative_df_2 = pd.DataFrame([negative_df[1],negative_df[0]]).transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P6GOa0nkl_j"
      },
      "outputs": [],
      "source": [
        "positive_df = pd.concat([positive_df,positive_df_2])\n",
        "negative_df = pd.concat([negative_df,negative_df_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmIlUX_Fkn6D"
      },
      "outputs": [],
      "source": [
        "positive_df[2] = 1\n",
        "negative_df[2] = 0\n",
        "data = pd.concat([positive_df, negative_df],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA2wtfrWkp7D"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac=1,random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj1ppMBXktPO"
      },
      "outputs": [],
      "source": [
        "data[0] = [protein_sequences[x] for x in data[0]]\n",
        "data[1] = [protein_sequences[x] for x in data[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vspjEu2Akvx4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s78l-Tsky8N"
      },
      "outputs": [],
      "source": [
        "sequences1 = data[0].values  # Amino acid sequences of protein 1\n",
        "sequences2 = data[1].values  # Amino acid sequences of protein 2\n",
        "labels = data[2].values     # Interaction labels (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TZbcQtwk0m8"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(char_level=True)  # Tokenize at character level\n",
        "tokenizer.fit_on_texts(sequences1 + sequences2)\n",
        "\n",
        "# Convert sequences to numerical tokens\n",
        "encoded_sequences1 = tokenizer.texts_to_sequences(sequences1)\n",
        "encoded_sequences2 = tokenizer.texts_to_sequences(sequences2)\n",
        "\n",
        "# Pad sequences to a fixed length (choose an appropriate maxlen)\n",
        "maxlen = 100  # Example max length, adjust as needed\n",
        "padded_sequences1 = pad_sequences(encoded_sequences1, maxlen=maxlen, padding='post')\n",
        "padded_sequences2 = pad_sequences(encoded_sequences2, maxlen=maxlen, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mygNymrck3PI"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size for embedding layer\n",
        "\n",
        "# Input layers for protein sequences\n",
        "input1 = Input(shape=(maxlen,))\n",
        "input2 = Input(shape=(maxlen,))\n",
        "\n",
        "# Embedding layers to represent amino acids as vectors\n",
        "embedding_layer = Embedding(vocab_size, 128)  # 128-dimensional embeddings\n",
        "embedded_sequences1 = embedding_layer(input1)\n",
        "embedded_sequences2 = embedding_layer(input2)\n",
        "\n",
        "# LSTM layers with additional hidden layers\n",
        "lstm_layer1 = LSTM(64, return_sequences=True)  # First LSTM layer with return_sequences=True\n",
        "lstm_layer2 = LSTM(64)  # Second LSTM layer\n",
        "\n",
        "lstm_output1 = lstm_layer1(embedded_sequences1)\n",
        "lstm_output1 = lstm_layer2(lstm_output1)  # Pass output of first LSTM to the second\n",
        "\n",
        "lstm_output2 = lstm_layer1(embedded_sequences2)\n",
        "lstm_output2 = lstm_layer2(lstm_output2)  # Pass output of first LSTM to the second\n",
        "\n",
        "# Concatenate LSTM outputs\n",
        "merged = concatenate([lstm_output1, lstm_output2])\n",
        "\n",
        "# Dense layers for classification\n",
        "output = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgQLaWoRlI_9",
        "outputId": "85d01d86-d500-4c54-bb12-bbdf1412e8ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 253ms/step - accuracy: 0.5282 - loss: 0.6896\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 264ms/step - accuracy: 0.5712 - loss: 0.6788\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 245ms/step - accuracy: 0.5700 - loss: 0.6739\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 250ms/step - accuracy: 0.5880 - loss: 0.6703\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 256ms/step - accuracy: 0.6126 - loss: 0.6551\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 249ms/step - accuracy: 0.6033 - loss: 0.6546\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 247ms/step - accuracy: 0.6473 - loss: 0.6272\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 249ms/step - accuracy: 0.6790 - loss: 0.5991\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 259ms/step - accuracy: 0.6984 - loss: 0.5767\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 246ms/step - accuracy: 0.7501 - loss: 0.5102\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 247ms/step - accuracy: 0.7992 - loss: 0.4459\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 262ms/step - accuracy: 0.8434 - loss: 0.3716\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 246ms/step - accuracy: 0.8793 - loss: 0.3023\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 248ms/step - accuracy: 0.9064 - loss: 0.2449\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 249ms/step - accuracy: 0.9341 - loss: 0.1889\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 258ms/step - accuracy: 0.9409 - loss: 0.1725\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 249ms/step - accuracy: 0.9671 - loss: 0.1147\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 0.9557 - loss: 0.1269\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 252ms/step - accuracy: 0.9775 - loss: 0.0804\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 247ms/step - accuracy: 0.9834 - loss: 0.0628\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step\n",
            "Fold 1 - Accuracy: 0.8878\n",
            "Fold 2\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 253ms/step - accuracy: 0.9364 - loss: 0.1871\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 254ms/step - accuracy: 0.9679 - loss: 0.1036\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 263ms/step - accuracy: 0.9914 - loss: 0.0479\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 245ms/step - accuracy: 0.9949 - loss: 0.0339\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 246ms/step - accuracy: 0.9971 - loss: 0.0227\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 252ms/step - accuracy: 0.9368 - loss: 0.1680\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 254ms/step - accuracy: 0.9887 - loss: 0.0451\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 254ms/step - accuracy: 0.9970 - loss: 0.0202\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 250ms/step - accuracy: 0.9973 - loss: 0.0163\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 0.0065\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 9.1330e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 7.7508e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 6.7275e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step\n",
            "Fold 2 - Accuracy: 0.9750\n",
            "Fold 3\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 257ms/step - accuracy: 0.8255 - loss: 0.4806\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 253ms/step - accuracy: 0.9150 - loss: 0.2222\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 258ms/step - accuracy: 0.9779 - loss: 0.0749\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 265ms/step - accuracy: 0.9976 - loss: 0.0279\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 256ms/step - accuracy: 0.9977 - loss: 0.0182\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0095\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 260ms/step - accuracy: 0.9998 - loss: 0.0042\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 8.9184e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 7.2791e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 6.0202e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 5.1641e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 4.5119e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 4.1421e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 3.3473e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step\n",
            "Fold 3 - Accuracy: 0.9840\n",
            "Fold 4\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 256ms/step - accuracy: 0.8289 - loss: 0.5110\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 266ms/step - accuracy: 0.9585 - loss: 0.1238\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 250ms/step - accuracy: 0.9936 - loss: 0.0381\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 257ms/step - accuracy: 0.9992 - loss: 0.0178\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 266ms/step - accuracy: 0.9992 - loss: 0.0142\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0049\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 8.7076e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 7.0114e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 6.3583e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 5.2468e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 4.4722e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 3.8384e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 3.3641e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 2.7664e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step\n",
            "Fold 4 - Accuracy: 0.9830\n",
            "Fold 5\n",
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 251ms/step - accuracy: 0.8493 - loss: 0.4624\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 249ms/step - accuracy: 0.9566 - loss: 0.1224\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 0.9936 - loss: 0.0349\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0119\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0066\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 9.8616e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 8.7370e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 6.7864e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 6.1512e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 5.0458e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 4.4471e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 3.5567e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 3.2017e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 2.6876e-04\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step\n",
            "Fold 5 - Accuracy: 0.9860\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the number of folds\n",
        "k = 5  # You can adjust this value\n",
        "\n",
        "# Create KFold object\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)  # Shuffle and set random_state for reproducibility\n",
        "\n",
        "# Lists to store evaluation results\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate through folds\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(padded_sequences1)):  # Assuming padded_sequences1 and padded_sequences2 have the same length\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    # Split data into training and testing sets for this fold\n",
        "    train_sequences1_fold, test_sequences1_fold = padded_sequences1[train_index], padded_sequences1[test_index]\n",
        "    train_sequences2_fold, test_sequences2_fold = padded_sequences2[train_index], padded_sequences2[test_index]\n",
        "    train_labels_fold, test_labels_fold = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Train the model on this fold's training data\n",
        "    model.fit([train_sequences1_fold, train_sequences2_fold], train_labels_fold, epochs=20, batch_size=32)\n",
        "\n",
        "    # Evaluate the model on this fold's testing data\n",
        "    predictions = model.predict([test_sequences1_fold, test_sequences2_fold])\n",
        "    predicted_labels_fold = (predictions > 0.5).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(test_labels_fold, predicted_labels_fold)\n",
        "    precision = precision_score(test_labels_fold, predicted_labels_fold)\n",
        "    recall = recall_score(test_labels_fold, predicted_labels_fold)\n",
        "    f1 = f1_score(test_labels_fold, predicted_labels_fold)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Fold {fold + 1} - Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah0qsH98lX9J",
        "outputId": "59f00982-45e5-483d-e9d4-2efed52ef041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.9631\n",
            "Average Precision: 0.9668\n",
            "Average Recalls: 0.9591\n",
            "Average F1 Scores: 0.9629\n"
          ]
        }
      ],
      "source": [
        "# Calculate average accuracy and loss across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recalls = np.mean(recalls)\n",
        "average_f1_scores = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {average_precision:.4f}\")\n",
        "print(f\"Average Recalls: {average_recalls:.4f}\")\n",
        "print(f\"Average F1 Scores: {average_f1_scores:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
